{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38acea94",
   "metadata": {},
   "source": [
    "# Two Asset HANK Model [<cite data-cite=\"6202365/ECL3ZAR7\"></cite>](https://cepr.org/active/publications/discussion_papers/dp.php?dpno=13071)\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/econ-ark/HARK/BayerLuetticke/notebooks?filepath=HARK%2FBayerLuetticke%2FTwoAsset.ipynb)\n",
    "\n",
    "- Adapted from original slides by Christian Bayer and Ralph Luetticke (Henceforth, 'BL')\n",
    "- Jupyter notebook originally by Seungcheol Lee\n",
    "- Further edits by Chris Carroll, Tao Wang, Edmund Crawley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934c4e71",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "BL propose a method for solving Heterogeneous Agent DSGE models that uses fast tools originally employed for image and video compression to speed up a variant of the solution methods proposed by Michael Reiter. <cite data-cite=\"undefined\"></cite>\n",
    "\n",
    "The Bayer-Luetticke method has the following broad features:\n",
    "   * The model is formulated and solved in discrete time (in contrast with some other recent approaches <cite data-cite=\"6202365/WN76AW6Q\"></cite>)\n",
    "   * Solution begins by calculation of the steady-state equilibrium (StE) with no aggregate shocks\n",
    "   * Both the representation of the consumer's problem and the desciption of the distribution are subjected to a form of [\"dimensionality reduction\"](https://en.wikipedia.org/wiki/Dimensionality_reduction)\n",
    "      * This means finding a way to represent these objects efficiently using fewer points\n",
    "   * \"Dimensionality reduction\" of the consumer's decision problem is performed before any further analysis is done\n",
    "      * This involves finding a representation of the policy functions using some class of [\"basis functions\"](https://en.wikipedia.org/wiki/Basis_function)\n",
    "   * Dimensionality reduction of the joint distribution is accomplished using a [\"copula\"](https://en.wikipedia.org/wiki/Copula_(probability_theory))\n",
    "      * See the companion notebook \"DCT-Copula-Illustration\" for a detailed description of the copula\n",
    "   * The method approximates the business-cycle-induced _deviations_ of the individual policy functions from those that characterize the riskless StE\n",
    "      * This is done using the same basis functions originally optimized to match the StE individual (micro) policy function\n",
    "      * The method of capturing dynamic deviations from a reference frame is akin to video compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fc53a",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "#### The Recursive Dynamic Planning Problem\n",
    "\n",
    "BL describe their problem a generic way; here, we will illustrate the meaning of their derivations and notation using the familiar example of the Krusell-Smith model, henceforth KS.  <cite data-cite=\"6202365/VPUXICUR\"></cite>\n",
    "\n",
    "Consider a household problem in presence of aggregate and idiosyncratic risk\n",
    "   * $S_t$ measures the (exogenous) aggregate state (e.g., levels of productivity and unemployment)\n",
    "   * $s_{it}$ records agent $i$'s idiosyncratic state (exogenous and endogenous, e.g. employment or assets)\n",
    "   * $\\mu_t$ is the distribution over $s$ at date $t$ (e.g., the wealth distribution)\n",
    "   * $P_{t}$ is the pricing kernel\n",
    "      * It captures the info about the aggregate state that the consumer needs to know in order to behave optimally\n",
    "      * e.g., KS showed that for their problem, a good _approximation_ to $P_{t}$ could be constructed\n",
    "        using only the economy's 'good/bad' state and the aggregate capital stock $K_{t}$\n",
    "   * $\\Gamma$ defines the budget set\n",
    "      * This delimits the set of feasible choices $x$ that the agent can make\n",
    "\n",
    "The Bellman equation is:\n",
    "\n",
    "\\begin{equation}\n",
    "        v(s_{it},S_t,\\mu_t) = \\max\\limits_{x \\in \\Gamma(s_{it},P_t)} u(s_{it},x) + \\beta \\mathbb{E}_{t} v(s_{it+1}(x,s_{it}),S_{t+1},\\mu_{t+1})\n",
    "\\end{equation}\n",
    "\n",
    "which, for many types of problems, implies a corresponding Euler equation: <!-- Question: Why isn't R a t+1 dated variable (and inside the expectations operator? -->\n",
    "     \\begin{equation}\n",
    "        u^{\\prime}\\left(s_{it},x(s_{it},S_t,\\mu_t)\\right) = \\beta \\mathbb{E}_{t} R(S_t,S_{t+1},\\mu_t,\\mu_{t+1}) u^{\\prime}\\left(s_{it+1},x(s_{it+1},S_{t+1},\\mu_{t+1})\\right)\n",
    "     \\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69576f",
   "metadata": {},
   "source": [
    "#### Solving for the StE\n",
    "\n",
    "The steady-state equilibrium is the one that will come about if there are no aggregate risks (and consumers know this)\n",
    "\n",
    "The first step in solving the full model is to solve for the steady-state:\n",
    "   * Discretize the state space\n",
    "      * Representing the nodes of the discretization in a set of vectors\n",
    "      * Such vectors will be represented by an overbar\n",
    "      * For example, the vectors $\\bar{s}_{it}$ and $\\bar{c}_{it}$ define a set of points on the policy function (the consumption function)\n",
    "   * The optimal policy $\\newcommand{\\policy}{c}\\newcommand{\\Policy}{C}\\policy(s_{it};P(\\mu))$ induces flow utility $u_{\\policy}$ whose discretization is a vector $\\bar{u}_{\\bar{\\policy}}$\n",
    "   * Idiosyncratic dynamics are captured by a transition probability matrix $\\Pi_{\\bar{\\policy}}$\n",
    "       * $\\Pi$ is like an expectations operator\n",
    "           * Given the consumer's state in $t$ it measures the probability of being in any other state in period $t+1$\n",
    "       * It depends on the vectorization of the policy function $\\bar{\\policy}$\n",
    "   * $P$ is constant because in StE aggregate prices are constant\n",
    "       * e.g., in the KS problem, $P$ would contain the (constant) wage and interest rates\n",
    "   * In StE, the discretized Bellman equation that if $\\bar{v}$ measures value at the discretized nodes,\n",
    "     \\begin{equation}\n",
    "        \\bar{v} = \\bar{u} + \\beta \\Pi_{\\bar{\\policy}}\\bar{v}\n",
    "      \\end{equation}\n",
    "     holds for the optimal policy\n",
    "   * For the distribution $\\mu$ of consumers across states, which (by the definition of steady state) is constant:\n",
    "\\begin{eqnarray}\n",
    "        \\bar{\\mu} & = & \\bar{\\mu} \\Pi_{\\bar{\\policy}} \\\\\n",
    "             d\\bar{\\mu} & = & d\\bar{\\mu} \\Pi_{\\bar{\\policy}}\n",
    "\\end{eqnarray}<!--     where we differentiate in the second line because we will be representing the distribution as a histogram, which counts the _extra_ population obtained by moving up --> <!-- Is this right?  $\\mu$ vs $d \\mu$ is a bit confusing.  The d is wrt the state, not time, right? -->\n",
    "\n",
    "We will define an approximate equilibrium in which:\n",
    "   * $\\bar{\\policy}$ is the vector that defines a linear interpolating policy function $\\policy$ at the state nodes\n",
    "       * given $P$ and $v$\n",
    "       * $v$ is a linear interpolation of $\\bar{v}$\n",
    "   * $\\bar{v}$ and $d\\bar{\\mu}$ solve the approximated Bellman equation\n",
    "       * subject to the steady-state constraint\n",
    "   * Markets clear ($\\exists$ joint requirement on $\\bar{\\policy}$, $\\mu$, and $P$; denoted as $\\Phi(\\bar{\\policy}, \\mu, P) = 0$)  <!-- Question: Why is this not $\\bar{\\mu}$ -->\n",
    "\n",
    "This can be solved by:\n",
    "   1. Given $P$,\n",
    "       1. Finding $d\\bar{\\mu}$ as the unit-eigenvalue of $\\Pi_{\\bar{\\policy}}$\n",
    "       2. Using standard solution techniques to solve the micro decision problem\n",
    "          * Given, e.g., that the aggregate wage and interest rate are constant\n",
    "   2. Using a root-finder to solve for $P$\n",
    "      * This basically iterates the other two steps until it finds values where they are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc148e",
   "metadata": {},
   "source": [
    "####  Introducing aggregate risk\n",
    "\n",
    "With aggregate risk\n",
    "   * Prices $P$ and the distribution $\\mu$ change over time\n",
    "\n",
    "Yet, for the household:\n",
    "   * Only prices and continuation values matter\n",
    "   * The distribution does not influence decisions directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1cf445",
   "metadata": {},
   "source": [
    "#### Sequential Equilibrium (Reiter, 2002)\n",
    "A 'sequential equilibrium with recursive individual planning'  <cite data-cite=\"6202365/UKUXJHCN\"></cite> is:\n",
    "   * A sequence of discretized Bellman equations, such that\n",
    "     \\begin{equation}\n",
    "        v_t = \\bar{u}_{P_t} + \\beta \\Pi_{\\policy_t} v_{t+1}\n",
    "     \\end{equation}\n",
    "     holds for policy $\\policy_t$ which optimizes with respect to $v_{t+1}$ and $P_t$\n",
    "   * and a sequence of \"histograms\" $d \\mu$ (discretized distributions), such that\n",
    "     \\begin{equation}\n",
    "        d\\mu_{t+1} = d\\mu_t \\Pi_{\\policy_t}\n",
    "     \\end{equation}\n",
    "     holds given the policy $h_{t}$, that is optimal given $P_t$, $v_{t+1}$\n",
    "     * That is, given a histogram describing the distribution in period $t$, $d \\mu_{t}$, next period's histogram is determined by the transition matrix\n",
    "   * Prices, distribution, and policies lead to market clearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13abb059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d292fd5b",
   "metadata": {},
   "source": [
    "#### Compact notation\n",
    "\n",
    "It will be convenient to rewrite the problem using a compact notation proposed by Schmidt-Grohe and Uribe (2004)\n",
    "\n",
    "The equilibrium conditions can be represented as a non-linear difference equation\n",
    "   * Controls: $Y_t = [v_t \\ P_t \\ Z_t^Y]$ and States: $X_t=[\\mu_t \\ S_t \\ Z_t^X]$\n",
    "      * where $Z_t$ are purely aggregate states/controls\n",
    "   * Define <!-- Q: What is $\\epsilon$ here? Why is it not encompassed in S_{t+1}? -->\n",
    "     \\begin{align}\n",
    "      F(d\\mu_t, S_t, d\\mu_{t+1}, S_{t+1}, v_t, P_t, v_{t+1}, P_{t+1}, \\epsilon_{t+1})\n",
    "      &= \\begin{bmatrix}\n",
    "           d\\mu_{t+1} - d\\mu_t\\Pi_{\\policy_t} \\\\\n",
    "           v_t - (u_{\\policy_t} + \\beta \\Pi_{\\policy_t}v_{t+1}) \\\\\n",
    "           S_{t+1} - \\Policy(S_t,d\\mu_t,\\epsilon_{t+1}) \\\\\n",
    "           \\Phi(\\policy_t,d\\mu_t,P_t,S_t) \\\\\n",
    "           \\epsilon_{t+1}\n",
    "           \\end{bmatrix}\n",
    "     \\end{align}\n",
    "     s.t. <!-- Q: Why are S_{t+1} and \\epsilon_{t+1} not arguments of v_{t+1} below? -->\n",
    "     \\begin{equation}\n",
    "     \\policy_t(s_{t}) = \\arg \\max\\limits_{x \\in \\Gamma(s,P_t)} u(s,x) + \\beta \\mathop{\\mathbb{E}_{t}} v_{t+1}(s_{t+1})\n",
    "     \\end{equation}\n",
    "   * The solution is a function-valued difference equation:\n",
    "\\begin{equation}\n",
    "     \\mathop{\\mathbb{E}_{t}}F(X_t,X_{t+1},Y_t,Y_{t+1},\\epsilon_{t+1}) = 0\n",
    "\\end{equation}\n",
    "     where $\\mathop{\\mathbb{E}}$ is the expectation over aggregate states\n",
    "   * It becomes real-valued when we replace the functions by their discretized counterparts\n",
    "   * Standard techniques can solve the discretized version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be9bd5c",
   "metadata": {},
   "source": [
    "#### So, is all solved?\n",
    "The dimensionality of the system F is a big problem\n",
    "   * With high dimensional idiosyncratic states, discretized value functions and distributions become large objects\n",
    "   * For example:\n",
    "      * 4 income states $\\times$ 100 illiquid capital states $\\times$ 100 liquid capital states $\\rightarrow$ $\\geq$ 40,000 values in $F$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8619d0a",
   "metadata": {},
   "source": [
    "### Bayer-Luetticke method\n",
    "#### Idea:\n",
    "1. Use compression techniques as in video encoding\n",
    "   * Apply a [discrete cosine transformation](https://en.wikipedia.org/wiki/Discrete_cosine_transform) (DCT) to all value/policy functions\n",
    "      * DCT is used because it is the default in the video encoding literature\n",
    "      * Choice of cosine is unimportant\n",
    "         * linear basis functions might work just as well\n",
    "      * This lets us represent the functions with many fewer points\n",
    "   * Fluctuations are represented as differences from this reference frame\n",
    "   * Assume all coefficients of the DCT from the StE that are close to zero do not change when there is an aggregate shock (small things stay small)\n",
    "\n",
    "2. Assume no changes in the rank correlation structure of $\\mu$\n",
    "   * $\\Rightarrow d\\mu $ can be represented by a Copula\n",
    "   * Calculate the Copula, $\\bar{C}$ of $\\mu$ in the StE\n",
    "   * Perturb only the marginal distributions\n",
    "      * This assumes that the rank correlations remain the same\n",
    "      * See the companion notebook for more discussion of this\n",
    "   * Use fixed Copula to calculate an approximate joint distribution from marginals\n",
    "\n",
    "\n",
    "The approach follows the insight of KS in that it uses the fact that some moments of the distribution do not matter for aggregate dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4cbb4",
   "metadata": {},
   "source": [
    "#### Details\n",
    "1) Compression techniques from video encoding\n",
    "   * Let $\\bar{\\Theta} = dct(\\bar{v})$ be the coefficients obtained from the DCT of the value function in StE\n",
    "   * Define an index set $\\mathop{I}$ that contains the x percent largest (i.e. most important) elements from $\\bar{\\Theta}$\n",
    "   * Let $\\theta$ be a sparse vector with non-zero entries only for elements $i \\in \\mathop{I}$\n",
    "   * Define\n",
    "   \\begin{equation}\n",
    "    \\tilde{\\Theta}(\\theta_t)=\\left\\{\n",
    "      \\begin{array}{@{}ll@{}}\n",
    "         \\bar{\\Theta}(i)+\\theta_t(i), & i \\in \\mathop{I} \\\\\n",
    "              \\bar{\\Theta}(i), & \\text{else}\n",
    "      \\end{array}\\right.\n",
    "   \\end{equation}\n",
    "   * This assumes that the basis functions with least contribution to representation of the function in levels, make no contribution at all to its changes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d0d1a",
   "metadata": {},
   "source": [
    "2) Decoding\n",
    "   * Now we reconstruct $\\tilde{v}(\\theta_t)=dct^{-1}(\\tilde{\\Theta}(\\theta_{t}))$\n",
    "      * idct=$dct^{-1}$ is the inverse dct that goes from the $\\theta$ vector to the corresponding values\n",
    "   * This means that in the StE the reduction step adds no addtional approximation error:\n",
    "       * Remember that $\\tilde{v}(0)=\\bar{v}$ by construction\n",
    "   * But it allows us to reduce the number of derivatives that need to be calculated from the outset.\n",
    "       * We only calculate derivatives for those basis functions that make an important contribution to the representation of the function\n",
    "\n",
    "3) The histogram is recovered as follows\n",
    "   * $\\mu_t$ is approximated as $\\bar{C}(\\bar{\\mu_t}^1,...,\\bar{\\mu_t}^n)$, where $n$ is the dimensionality of the idiosyncratic states <!-- Question: Why is there no time subscript on $\\bar{C}$?  I thought the copula was allowed to vary over time ... --> <!-- Question: is $\\mu_{t}$ linearly interpolated between gridpoints? ... -->\n",
    "      * $\\mu_t^{i}$ are the marginal distributions <!-- Question: These are cumulatives, right?  They are not in the same units as $\\mu$ -->\n",
    "   * The StE distribution is obtained when $\\mu = \\bar{C}(\\bar{\\mu}^1,...,\\bar{\\mu}^n)$\n",
    "   * Typically prices are only influenced through the marginal distributions\n",
    "   * The approach ensures that changes in the mass of one state (say, wealth) are distributed in a sensible way across the other dimensions\n",
    "      * Where \"sensible\" means \"like in StE\" <!-- Question: Right? -->\n",
    "   * The implied distributions look \"similar\" to the StE one (different in (Reiter, 2009))\n",
    "\n",
    "4) The large system above is now transformed into a much smaller system:\n",
    "     \\begin{align}\n",
    "      F(\\{d\\mu_t^1,...,d\\mu_t^n\\}, S_t, \\{d\\mu_{t+1}^1,...,d\\mu_{t+1}^n\\}, S_{t+1}, \\theta_t, P_t, \\theta_{t+1}, P_{t+1})\n",
    "      &= \\begin{bmatrix}\n",
    "           d\\bar{C}(\\bar{\\mu}_t^1,...,\\bar{\\mu}_t^n) - d\\bar{C}(\\bar{\\mu}_t^1,...,\\bar{\\mu}_t^n)\\Pi_{\\policy_t} \\\\\n",
    "                dct\\left[idct\\left(\\tilde{\\Theta}(\\theta_t) - (\\bar{u}_{\\policy_t} + \\beta \\Pi_{\\policy_t}idct(\\tilde{\\Theta}(\\theta_{t+1}))\\right)\\right] \\\\\n",
    "                S_{t+1} - \\Policy(S_t,d\\mu_t) \\\\\n",
    "                \\Phi(\\policy_t,d\\mu_t,P_t,S_t) \\\\\n",
    "                \\end{bmatrix}\n",
    "     \\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213c2dd",
   "metadata": {},
   "source": [
    "### The two-asset HANK model\n",
    "\n",
    "We illustrate the algorithm in a two-asset HANK model described as below\n",
    "\n",
    "\n",
    "#### Households\n",
    "- Maximizing discounted felicity\n",
    "   - Consumption $c$ \n",
    "      - CRRA coefficent: $\\xi$\n",
    "      - EOS of CES consumption bundle: $\\eta$\n",
    "   - Disutility from work in GHH form: \n",
    "     - Frisch elasticity $\\gamma$\n",
    "- Two assets:\n",
    "   - Liquid nominal bonds $b$, greater than lower bound $\\underline b$\n",
    "      - Borrowing constraint due to a wedge between borrowing and saving rate:  $R^b(b<0)=R^B(b>0)+\\bar R$  \n",
    "   - Illiquid assets capital $k$ nonnegative\n",
    "      - Trading of illiquid assets is subject to a friction governed by $v$, the fraction of agents who can trade\n",
    "      - If nontrading, receive dividend $r$ and depreciates by $\\tau$\n",
    "- Idiosyncratic labor productivity $h$: \n",
    "   - $h = 0$ for entrepreneur, only receive profits $\\Pi$\n",
    "   - $h = 1$ for labor, evolves according to an autoregressive process, \n",
    "     - $\\rho_h$ persistence parameter\n",
    "     - $\\epsilon^h$: idiosyncratic risk \n",
    "\n",
    "#### Production \n",
    "- Intermediate good producer \n",
    "    - CRS production with TFP $Z$\n",
    "    - Wage $W$\n",
    "    - Cost of capital $r+\\delta$\n",
    "- Reseller \n",
    "    - Rotemberg price setting: quadratic adjustment cost scalled by $\\frac{\\eta}{2\\kappa}$\n",
    "    - Constant discount factor $\\beta$\n",
    "    - Investment subject to Tobin's q adjustment cost $\\phi$ \n",
    "- Aggregate risks $\\Omega$ include \n",
    "   - TFP $Z$, AR(1) process with persistence of $\\rho^Z$ and shock $\\epsilon^Z$  \n",
    "   - Uncertainty \n",
    "   - Monetary policy\n",
    "- Central bank\n",
    "   - Taylor rule on nominal saving rate $R^B$: reacts to deviation of inflation from target by $\\theta_R$ \n",
    "   - $\\rho_R$: policy inertia\n",
    "   - $\\epsilon^R$: monetary policy shocks\n",
    "- Government (fiscal rule)\n",
    "   - Government spending $G$ \n",
    "   - Tax $T$ \n",
    "   - $\\rho_G$: intensity of repaying government debt: $\\rho_G=1$ implies roll-over \n",
    "\n",
    "#### Taking stock\n",
    "\n",
    "- Individual state variables: $\\newcommand{\\liquid}{m}\\liquid$, $k$ and $h$, the joint distribution of individual states $\\Theta$\n",
    "- Individual control variables: $c$, $n$, $\\liquid'$, $k'$ \n",
    "- Optimal policy for adjusters and nonadjusters are $c^*_a$, $n^*_a$ $k^*_a$ and $\\liquid^*_a$ and  $c^*_n$, $n^*_n$ and $\\liquid^*_n$, respectively \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7f289",
   "metadata": {
    "code_folding": [],
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Setup stuff \n",
    "\n",
    "\n",
    "# The tools for navigating the filesystem\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from copy import copy\n",
    "# Ignore scary but unimportant system warnings while running the notebook\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d5529f",
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code must be inside a main() block to be usable for multiprocessing from command line\n",
    "# Jupyter notebooks ignore the multiprocessing (so are slower)\n",
    "def main():\n",
    "\n",
    "    # Find pathname to this file:\n",
    "\n",
    "    # This is a jupytext paired notebook that autogenerates a corresponding .py file\n",
    "    # which can be executed from a terminal command line via \"ipython [name].py\"\n",
    "    # But a terminal does not permit inline figures, so we need to test jupyter vs terminal\n",
    "    # Google \"how can I check if code is executed in the ipython notebook\"\n",
    "    \n",
    "    def in_ipynb():\n",
    "        try:\n",
    "            if str(type(get_ipython())) == \"<class 'ipykernel.zmqshell.ZMQInteractiveShell'>\":\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except NameError:\n",
    "            return False\n",
    "    \n",
    "    # Determine whether to make the figures inline (for spyder or jupyter)\n",
    "    # vs whatever is the automatic setting that will apply if run from the terminal\n",
    "    if in_ipynb():\n",
    "        # matplotlib inline generates a syntax error when run from the shell\n",
    "        # so do this instead\n",
    "        get_ipython().run_line_magic('matplotlib', 'inline') \n",
    "    else:\n",
    "        from matplotlib.pyplot import ion\n",
    "        ion()\n",
    "        get_ipython().run_line_magic('matplotlib', 'auto') \n",
    "\n",
    "    my_file_path = os.path.dirname(os.path.abspath(\"TwoAsset-HANK.py\"))\n",
    "    \n",
    "    # Relative and absolute paths for pickled code\n",
    "    code_dir_rel = os.path.join(my_file_path, \"../Assets/Two\") \n",
    "    code_dir = os.path.abspath(code_dir_rel)\n",
    "    \n",
    "    sys.path.insert(0, code_dir)\n",
    "    sys.path.insert(0, my_file_path)\n",
    "    \n",
    "    ## Load precomputed Stationary Equilibrium (StE) object EX3SS_20\n",
    "    \n",
    "    os.chdir(code_dir) # Go to the directory with pickled code\n",
    "    \n",
    "    ## EX3SS_20.p is the information in the stationary equilibrium \n",
    "    ## (20: the number of illiquid and liquid weath gridpoints )\n",
    "    EX3SS=pickle.load(open(\"EX3SS_20.p\", \"rb\"))\n",
    "\n",
    "    from FluctuationsTwoAsset import FluctuationsTwoAsset, SGU_solver, plot_IRF\n",
    "    \n",
    "    start_time = time.perf_counter() \n",
    "    \n",
    "    ## Choose one of three aggregate shocks to perturb\n",
    "    ## MP (monetary policy)\n",
    "    ## TFP (total factor productivity)\n",
    "    ## Uncertainty\n",
    "    \n",
    "    # EX3SS['par']['aggrshock']           = 'MP'\n",
    "    # EX3SS['par']['rhoS']    = 0.0      # Persistence of variance\n",
    "    # EX3SS['par']['sigmaS']  = 0.001    # STD of variance shocks\n",
    "    \n",
    "    # EX3SS['par']['aggrshock']           = 'TFP'\n",
    "    # EX3SS['par']['rhoS']    = 0.95\n",
    "    # EX3SS['par']['sigmaS']  = 0.0075\n",
    "        \n",
    "    EX3SS['par']['aggrshock'] = 'Uncertainty'\n",
    "    EX3SS['par']['rhoS'] = 0.84      # Persistence of variance\n",
    "    EX3SS['par']['sigmaS'] = 0.54    # STD of variance shocks\n",
    "    \n",
    "    ## Choose an accuracy of approximation with DCT\n",
    "    ### Determines number of basis functions chosen -- enough to match this accuracy\n",
    "    ### EX3SS is precomputed steady-state pulled in above\n",
    "    EX3SS['par']['accuracy'] = 0.99999 \n",
    "    \n",
    "    ## Implement state reduction and DCT\n",
    "    ### Do state reduction on steady state\n",
    "    \n",
    "    EX3SR = FluctuationsTwoAsset(**EX3SS)\n",
    "    SR = EX3SR.StateReduc()\n",
    "    \n",
    "    print('SGU_solver')\n",
    "    SGUresult = SGU_solver(SR['Xss'],SR['Yss'],SR['Gamma_state'],SR['indexMUdct'],SR['indexVKdct'],SR['par'],SR['mpar'],SR['grid'],SR['targets'],SR['Copula'],SR['P_H'],SR['aggrshock'])\n",
    "    print('plot_IRF')\n",
    "    plot_IRF(SR['mpar'],SR['par'],SGUresult['gx'],SGUresult['hx'],SR['joint_distr'],\n",
    "             SR['Gamma_state'],SR['grid'],SR['targets'],SR['Output'])\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    print('Elapsed time is ',  (end_time-start_time), ' seconds.')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
